{"cells":[{"cell_type":"markdown","source":["## Overview\n\nThis notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n\nThis notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96816ed7-b08a-4ca3-abb9-f99880c3535d"}}},{"cell_type":"code","source":["# File location and type\nfile_location = \"/FileStore/tables/Employee_info_1.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"false\"\nfirst_row_is_header = \"false\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ndf = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(file_location)\n\ndisplay(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6482be4c-f067-47c9-b0ac-35c938b94601"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# Create a view or table\n\ntemp_table_name = \"Employee_info_1_csv\"\n\ndf.createOrReplaceTempView(temp_table_name)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bd82bb99-1479-4d5c-be10-8c36df0f1d44"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n\n/* Query the created temp table in a SQL cell */\n\nselect * from `Employee_info_1_csv`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5f66379-6f7f-42ec-8e82-d0e0926a1721"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# With this registered as a temp view, it will only be available to this particular notebook. If you'd like other users to be able to query this table, you can also create a table from the DataFrame.\n# Once saved, this table will persist across cluster restarts as well as allow various users across different notebooks to query this data.\n# To do so, choose your table name and uncomment the bottom line.\n\npermanent_table_name = \"Employee_info_1_csv\"\n\n# df.write.format(\"parquet\").saveAsTable(permanent_table_name)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db9631f6-bb4a-42ca-8a3c-0d48af932331"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["\"\"\"\nAssignment 1 Spark ~ Aman Sir\n\nCreate 2 data frame and and join them.\n\nCreate a dataframe and replace the null values of a column with some meaningful thing using withcolumn.\n\nNote: Please use below csv to create data frame.\n\nCSV FILES - Employee_info.csv & Employee_info_1.csv\n\"\"\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Spark Assignment 1","showTitle":true,"inputWidgets":{},"nuid":"7531964d-611e-4850-8593-f7293caa0b42"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Importing pyspark Lib.\nimport pyspark\n\n#Making spark session\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('Assignment').getOrCreate()\n\n#About Spark\nspark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0317436e-fa6f-47ef-95f9-c5b0f6e58424"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=892183418903091#setting/sparkui/0730-101655-dk1vjrag/driver-3081779177900938303\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=892183418903091#setting/sparkui/0730-101655-dk1vjrag/driver-3081779177900938303\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":0},{"cell_type":"code","source":["#Reading single File\ndf1 = spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).option(\"sep\",\",\").load(\"/FileStore/tables/Employee_info.csv\")\n\ndisplay (df1)\n\nprint(df1.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"97f893df-93e9-4d65-a79a-92c7f5c2d8af"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[100,"Aman","Data Engineering"],[200,"Saurabh","Data Engineering"],[300,"Mohit","DavOps"],[400,"Kashif","DAvOps"],[500,"Eniya","DAvOps"],[600,"Anand","DAvOps"],[700,"Murali","Data Engineering"],[800,"Ramesh","Null"],[900,"Suresh","Null"],[1000,"Himanshu","Null"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Id","type":"\"integer\"","metadata":"{}"},{"name":"Name","type":"\"string\"","metadata":"{}"},{"name":"Department","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Id</th><th>Name</th><th>Department</th></tr></thead><tbody><tr><td>100</td><td>Aman</td><td>Data Engineering</td></tr><tr><td>200</td><td>Saurabh</td><td>Data Engineering</td></tr><tr><td>300</td><td>Mohit</td><td>DavOps</td></tr><tr><td>400</td><td>Kashif</td><td>DAvOps</td></tr><tr><td>500</td><td>Eniya</td><td>DAvOps</td></tr><tr><td>600</td><td>Anand</td><td>DAvOps</td></tr><tr><td>700</td><td>Murali</td><td>Data Engineering</td></tr><tr><td>800</td><td>Ramesh</td><td>Null</td></tr><tr><td>900</td><td>Suresh</td><td>Null</td></tr><tr><td>1000</td><td>Himanshu</td><td>Null</td></tr></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"10\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["10\n"]}}],"execution_count":0},{"cell_type":"code","source":["df1.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26bee27e-56e8-46f1-9504-ee64249bbdb6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- Id: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- Department: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- Id: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- Department: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, IntegerType, StringType\nschema_defined1 = StructType([StructField('Id', IntegerType(), True),\n                             StructField('Name', StringType(),True),\n                             StructField('Department', StringType(),True),\n                            ])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5496ed0d-bab8-4b63-a345-2f71b7b65e93"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_a= spark.read.format(\"csv\").schema(schema_defined1).option(\"header\", True ).option(\"sep\",\",\").load(\"/FileStore/tables/Employee_info.csv\")\ndisplay (df_a)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"704cd5c9-cdb2-45a1-a606-4c795c78d199"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[100,"Aman","Data Engineering"],[200,"Saurabh","Data Engineering"],[300,"Mohit","DavOps"],[400,"Kashif","DAvOps"],[500,"Eniya","DAvOps"],[600,"Anand","DAvOps"],[700,"Murali","Data Engineering"],[800,"Ramesh","Null"],[900,"Suresh","Null"],[1000,"Himanshu","Null"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Id","type":"\"integer\"","metadata":"{}"},{"name":"Name","type":"\"string\"","metadata":"{}"},{"name":"Department","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Id</th><th>Name</th><th>Department</th></tr></thead><tbody><tr><td>100</td><td>Aman</td><td>Data Engineering</td></tr><tr><td>200</td><td>Saurabh</td><td>Data Engineering</td></tr><tr><td>300</td><td>Mohit</td><td>DavOps</td></tr><tr><td>400</td><td>Kashif</td><td>DAvOps</td></tr><tr><td>500</td><td>Eniya</td><td>DAvOps</td></tr><tr><td>600</td><td>Anand</td><td>DAvOps</td></tr><tr><td>700</td><td>Murali</td><td>Data Engineering</td></tr><tr><td>800</td><td>Ramesh</td><td>Null</td></tr><tr><td>900</td><td>Suresh</td><td>Null</td></tr><tr><td>1000</td><td>Himanshu</td><td>Null</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Reading single File\ndf2 = spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).option(\"sep\",\",\").load(\"/FileStore/tables/Employee_info_1.csv\")\n\ndisplay (df2)\n\nprint(df2.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b1c0aff-819d-44b0-a2b9-dc5f539df278"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[100,2555,"Indore","MP"],[200,2456,"Indore","MP"],[300,3265,"Surat","GJ"],[400,7896,"Banglore","KA"],[500,4562,"Banglore","KA"],[600,8524,"Banglore","KA"],[700,6666,"Banglore","KA"],[800,9853,"Banglore","KA"],[900,1594,"Null","JK"],[1000,7894,"Null","JK"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Id","type":"\"integer\"","metadata":"{}"},{"name":"Employee_id","type":"\"integer\"","metadata":"{}"},{"name":"City","type":"\"string\"","metadata":"{}"},{"name":"State","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Id</th><th>Employee_id</th><th>City</th><th>State</th></tr></thead><tbody><tr><td>100</td><td>2555</td><td>Indore</td><td>MP</td></tr><tr><td>200</td><td>2456</td><td>Indore</td><td>MP</td></tr><tr><td>300</td><td>3265</td><td>Surat</td><td>GJ</td></tr><tr><td>400</td><td>7896</td><td>Banglore</td><td>KA</td></tr><tr><td>500</td><td>4562</td><td>Banglore</td><td>KA</td></tr><tr><td>600</td><td>8524</td><td>Banglore</td><td>KA</td></tr><tr><td>700</td><td>6666</td><td>Banglore</td><td>KA</td></tr><tr><td>800</td><td>9853</td><td>Banglore</td><td>KA</td></tr><tr><td>900</td><td>1594</td><td>Null</td><td>JK</td></tr><tr><td>1000</td><td>7894</td><td>Null</td><td>JK</td></tr></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"10\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["10\n"]}}],"execution_count":0},{"cell_type":"code","source":["df2.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2474a7f2-db92-4621-b19c-5f29eedf2d59"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- Id: integer (nullable = true)\n |-- Employee_id: integer (nullable = true)\n |-- City: string (nullable = true)\n |-- State: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- Id: integer (nullable = true)\n |-- Employee_id: integer (nullable = true)\n |-- City: string (nullable = true)\n |-- State: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, IntegerType, StringType\nschema_defined2 = StructType([StructField('Id',IntegerType(), True),\n                             StructField('Employee_id',IntegerType(),True),\n                             StructField('City',StringType(),True),\n                             StructField('State',StringType(),True),\n                            ])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"60ff2c12-6b5a-4b4e-b1dd-36c3235f7891"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_b= spark.read.format(\"csv\").schema(schema_defined2).option(\"header\", True ).option(\"sep\",\",\").load(\"/FileStore/tables/Employee_info_1.csv\")\ndisplay (df_a)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cef94b8c-c761-4e14-bf03-b8e6cb7be15b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[100,"Aman","Data Engineering"],[200,"Saurabh","Data Engineering"],[300,"Mohit","DavOps"],[400,"Kashif","DAvOps"],[500,"Eniya","DAvOps"],[600,"Anand","DAvOps"],[700,"Murali","Data Engineering"],[800,"Ramesh","Null"],[900,"Suresh","Null"],[1000,"Himanshu","Null"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Id","type":"\"integer\"","metadata":"{}"},{"name":"Name","type":"\"string\"","metadata":"{}"},{"name":"Department","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Id</th><th>Name</th><th>Department</th></tr></thead><tbody><tr><td>100</td><td>Aman</td><td>Data Engineering</td></tr><tr><td>200</td><td>Saurabh</td><td>Data Engineering</td></tr><tr><td>300</td><td>Mohit</td><td>DavOps</td></tr><tr><td>400</td><td>Kashif</td><td>DAvOps</td></tr><tr><td>500</td><td>Eniya</td><td>DAvOps</td></tr><tr><td>600</td><td>Anand</td><td>DAvOps</td></tr><tr><td>700</td><td>Murali</td><td>Data Engineering</td></tr><tr><td>800</td><td>Ramesh</td><td>Null</td></tr><tr><td>900</td><td>Suresh</td><td>Null</td></tr><tr><td>1000</td><td>Himanshu</td><td>Null</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["\"\"\"\nNow we have two dataframes with defined schema df_a & df_b\n\n\"\"\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2397816b-9c5c-449f-b5be-9d92a8cca200"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#join 'Full outer join'\ndf_join = df_a.join(df_b,df_a.Id == df_b.Id,\"outer\")\ndisplay(df_join)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7e2e15d-4d3f-469b-89e0-3e359b59f251"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[100,"Aman","Data Engineering",100,2555,"Indore","MP"],[200,"Saurabh","Data Engineering",200,2456,"Indore","MP"],[300,"Mohit","DavOps",300,3265,"Surat","GJ"],[400,"Kashif","DAvOps",400,7896,"Banglore","KA"],[500,"Eniya","DAvOps",500,4562,"Banglore","KA"],[600,"Anand","DAvOps",600,8524,"Banglore","KA"],[700,"Murali","Data Engineering",700,6666,"Banglore","KA"],[800,"Ramesh","Null",800,9853,"Banglore","KA"],[900,"Suresh","Null",900,1594,"Null","JK"],[1000,"Himanshu","Null",1000,7894,"Null","JK"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Id","type":"\"integer\"","metadata":"{}"},{"name":"Name","type":"\"string\"","metadata":"{}"},{"name":"Department","type":"\"string\"","metadata":"{}"},{"name":"Id","type":"\"integer\"","metadata":"{}"},{"name":"Employee_id","type":"\"integer\"","metadata":"{}"},{"name":"City","type":"\"string\"","metadata":"{}"},{"name":"State","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Id</th><th>Name</th><th>Department</th><th>Id</th><th>Employee_id</th><th>City</th><th>State</th></tr></thead><tbody><tr><td>100</td><td>Aman</td><td>Data Engineering</td><td>100</td><td>2555</td><td>Indore</td><td>MP</td></tr><tr><td>200</td><td>Saurabh</td><td>Data Engineering</td><td>200</td><td>2456</td><td>Indore</td><td>MP</td></tr><tr><td>300</td><td>Mohit</td><td>DavOps</td><td>300</td><td>3265</td><td>Surat</td><td>GJ</td></tr><tr><td>400</td><td>Kashif</td><td>DAvOps</td><td>400</td><td>7896</td><td>Banglore</td><td>KA</td></tr><tr><td>500</td><td>Eniya</td><td>DAvOps</td><td>500</td><td>4562</td><td>Banglore</td><td>KA</td></tr><tr><td>600</td><td>Anand</td><td>DAvOps</td><td>600</td><td>8524</td><td>Banglore</td><td>KA</td></tr><tr><td>700</td><td>Murali</td><td>Data Engineering</td><td>700</td><td>6666</td><td>Banglore</td><td>KA</td></tr><tr><td>800</td><td>Ramesh</td><td>Null</td><td>800</td><td>9853</td><td>Banglore</td><td>KA</td></tr><tr><td>900</td><td>Suresh</td><td>Null</td><td>900</td><td>1594</td><td>Null</td><td>JK</td></tr><tr><td>1000</td><td>Himanshu</td><td>Null</td><td>1000</td><td>7894</td><td>Null</td><td>JK</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Replacing 'NUll' with meaningfull\nfrom pyspark.sql.functions import regexp_replace\ndf_join.withColumn('City', regexp_replace('City', 'Null', 'Srinagar')) \\\n  .show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4d39284-75b1-480a-8465-bb9aff1589f1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+--------+----------------+----+-----------+--------+-----+\n|Id  |Name    |Department      |Id  |Employee_id|City    |State|\n+----+--------+----------------+----+-----------+--------+-----+\n|100 |Aman    |Data Engineering|100 |2555       |Indore  |MP   |\n|200 |Saurabh |Data Engineering|200 |2456       |Indore  |MP   |\n|300 |Mohit   |DavOps          |300 |3265       |Surat   |GJ   |\n|400 |Kashif  |DAvOps          |400 |7896       |Banglore|KA   |\n|500 |Eniya   |DAvOps          |500 |4562       |Banglore|KA   |\n|600 |Anand   |DAvOps          |600 |8524       |Banglore|KA   |\n|700 |Murali  |Data Engineering|700 |6666       |Banglore|KA   |\n|800 |Ramesh  |Null            |800 |9853       |Banglore|KA   |\n|900 |Suresh  |Null            |900 |1594       |Srinagar|JK   |\n|1000|Himanshu|Null            |1000|7894       |Srinagar|JK   |\n+----+--------+----------------+----+-----------+--------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+--------+----------------+----+-----------+--------+-----+\n|Id  |Name    |Department      |Id  |Employee_id|City    |State|\n+----+--------+----------------+----+-----------+--------+-----+\n|100 |Aman    |Data Engineering|100 |2555       |Indore  |MP   |\n|200 |Saurabh |Data Engineering|200 |2456       |Indore  |MP   |\n|300 |Mohit   |DavOps          |300 |3265       |Surat   |GJ   |\n|400 |Kashif  |DAvOps          |400 |7896       |Banglore|KA   |\n|500 |Eniya   |DAvOps          |500 |4562       |Banglore|KA   |\n|600 |Anand   |DAvOps          |600 |8524       |Banglore|KA   |\n|700 |Murali  |Data Engineering|700 |6666       |Banglore|KA   |\n|800 |Ramesh  |Null            |800 |9853       |Banglore|KA   |\n|900 |Suresh  |Null            |900 |1594       |Srinagar|JK   |\n|1000|Himanshu|Null            |1000|7894       |Srinagar|JK   |\n+----+--------+----------------+----+-----------+--------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import regexp_replace\ndf_join.withColumn('Department', regexp_replace('Department', 'Null', 'Other')) \\\n  .show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d1b6687-db3e-40cb-81e4-86aa43b0f02a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+--------+----------------+----+-----------+--------+-----+\n|Id  |Name    |Department      |Id  |Employee_id|City    |State|\n+----+--------+----------------+----+-----------+--------+-----+\n|100 |Aman    |Data Engineering|100 |2555       |Indore  |MP   |\n|200 |Saurabh |Data Engineering|200 |2456       |Indore  |MP   |\n|300 |Mohit   |DavOps          |300 |3265       |Surat   |GJ   |\n|400 |Kashif  |DAvOps          |400 |7896       |Banglore|KA   |\n|500 |Eniya   |DAvOps          |500 |4562       |Banglore|KA   |\n|600 |Anand   |DAvOps          |600 |8524       |Banglore|KA   |\n|700 |Murali  |Data Engineering|700 |6666       |Banglore|KA   |\n|800 |Ramesh  |Other           |800 |9853       |Banglore|KA   |\n|900 |Suresh  |Other           |900 |1594       |Null    |JK   |\n|1000|Himanshu|Other           |1000|7894       |Null    |JK   |\n+----+--------+----------------+----+-----------+--------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+--------+----------------+----+-----------+--------+-----+\n|Id  |Name    |Department      |Id  |Employee_id|City    |State|\n+----+--------+----------------+----+-----------+--------+-----+\n|100 |Aman    |Data Engineering|100 |2555       |Indore  |MP   |\n|200 |Saurabh |Data Engineering|200 |2456       |Indore  |MP   |\n|300 |Mohit   |DavOps          |300 |3265       |Surat   |GJ   |\n|400 |Kashif  |DAvOps          |400 |7896       |Banglore|KA   |\n|500 |Eniya   |DAvOps          |500 |4562       |Banglore|KA   |\n|600 |Anand   |DAvOps          |600 |8524       |Banglore|KA   |\n|700 |Murali  |Data Engineering|700 |6666       |Banglore|KA   |\n|800 |Ramesh  |Other           |800 |9853       |Banglore|KA   |\n|900 |Suresh  |Other           |900 |1594       |Null    |JK   |\n|1000|Himanshu|Other           |1000|7894       |Null    |JK   |\n+----+--------+----------------+----+-----------+--------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"055f7c09-470e-43a4-94e7-fe072eee9c57"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Spark Assignment 1","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3047202937215288}},"nbformat":4,"nbformat_minor":0}
